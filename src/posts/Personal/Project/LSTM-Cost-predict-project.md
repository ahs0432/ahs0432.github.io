---
title:  "[Project] \"í´ë¼ìš°ë“œ ë¹„ìš© ì˜ˆì¸¡\" í”„ë¡œì íŠ¸ íšŒê³ "

categories:
  - Project
tags:
  - Project
  - í”„ë¡œì íŠ¸
  - ì¸ê³µì§€ëŠ¥
  - AI
  - ë¹…ë°ì´í„°
  - Big Data
  - Regression
  - ì„ í˜•íšŒê·€
  - íšŒê·€
  - Prophet
  - Meta
  - LSTM
  - RNN
  - ìˆœí™˜ì‹ ê²½ë§
  - ìˆœí™˜
  - Timeseries
  - ì‹œê³„ì—´
  - ì‹œê³„ì—´ë°ì´í„°

date: 2025-01-01

editLink: false
lastUpdated: true
---

::: info
ğŸ“¢ í˜„ì¬ í¬ìŠ¤íŒ…ì€ 2024ë…„ 2í•™ê¸°ì— ì§„í–‰í•œ `ê°œì¸ í”„ë¡œì íŠ¸`ì— ëŒ€í•œ íšŒê³ ì…ë‹ˆë‹¤.
:::

## ğŸ¨ í”„ë¡œì íŠ¸ ê°œìš”
ì €ëŠ” `í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤`ë¥¼ ì œê³µí•˜ëŠ” íšŒì‚¬ì— ê·¼ë¬´ ì¤‘ì´ë©° ë¹„ìš©ì— ëŒ€í•œ ì´ìŠˆë¥¼ ìì£¼ ì ‘í•˜ê²Œ ë©ë‹ˆë‹¤.  

ê°€ë” ìƒê°ë‚˜ëŠ” ë‚´ìš©ìœ¼ë¡œ `ë¹„ìš©ì˜ ì¶”ì´`ë¥¼ ë¯¸ë¦¬ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤ë©´ êµ‰ì¥íˆ ì¢‹ì„í…ë°ë¼ëŠ” ê³ ì•ˆì„ í•˜ì˜€ëŠ”ë°,  
ì´ëŸ° ë¹„ìš© ì˜ˆì¸¡ ë‚´ìš©ì„ `ì°¨íŠ¸` í˜•íƒœë¡œ ë§Œë“¤ì–´ ì‹¤ì œ ë¹„ìš©ê³¼ ë¹„êµí•´ë³´ë©´ ì–´ë–¨ê¹Œë¼ëŠ” ìƒê°ë„ í•˜ê²Œ ëìŠµë‹ˆë‹¤.

`ë”¥ëŸ¬ë‹`ì— ëŒ€í•´ ê³µë¶€í•˜ê³  ìˆëŠ” ì…ì¥ìœ¼ë¡œ ì–´ë–»ê²Œ êµ¬í˜„í• ê¹Œë€ ê³ ë¯¼ì„ í•˜ì˜€ê³  `í”„ë¡œì íŠ¸`ë¥¼ ê¸°íší–ˆìŠµë‹ˆë‹¤.

## âŒ› ê°œë°œ ê¸°ê°„
ë¹ ë¥´ê²Œ `í”„ë¡œì íŠ¸`ë¥¼ ìˆ˜í–‰í•˜ê³  ë§ˆë¬´ë¦¬í•˜ê¸° ìœ„í•´ì„œ ê¸°ê°„ì€ `í•™ìŠµ` ì‹œê°„ê¹Œì§€ í¬í•¨í•˜ì—¬ ì§§ê²Œ ì¡ì•„ë³´ì•˜ìŠµë‹ˆë‹¤.
- ì´ ê¸°ê°„: 2024.11.10 ~ 2024.11.20 (ì•½ 10ì¼)

## ğŸ’» ê¸°ìˆ  ìŠ¤íƒ
### ğŸ”§ ì–¸ì–´
<img src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="" loading="lazy" photo-swipe="" style="cursor: zoom-in;">

### ğŸ¦´ ë¼ì´ë¸ŒëŸ¬ë¦¬
<img src="https://img.shields.io/badge/Meta_prophet-0467DF?style=for-the-badge&logo=meta&logoColor=white" alt="" loading="lazy" photo-swipe="" style="cursor: zoom-in;">
<img src="https://img.shields.io/badge/pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="" loading="lazy" photo-swipe="" style="cursor: zoom-in;">
<img src="https://img.shields.io/badge/scikitlearn-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white" alt="" loading="lazy" photo-swipe="" style="cursor: zoom-in;">
<img src="https://img.shields.io/badge/Tensorflow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="" loading="lazy" photo-swipe="" style="cursor: zoom-in;">

## ğŸ¨ ë°ì´í„°ì…‹ ìˆ˜ì§‘ ë° ë¶„ì„
`ë°ì´í„°ì…‹`ì˜ ê²½ìš° ë¹„ìš©ì´ë‹¤ë³´ë‹ˆ ë¯¼ê° ìë£Œë¡œ ì‚¬ë‚´ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë¹„ìš©ì„ í† ëŒ€ë¡œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.  
ê³µê°œí•  ìˆ˜ëŠ” ì—†ì§€ë§Œ `ë°ì´í„°ë² ì´ìŠ¤`ì— ì €ì¥ëœ ë‚´ìš©ì„ `CSV` í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì´ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

ê¸°ê°„ìœ¼ë¡œëŠ” 2024.05~2024.10 ê¸°ê°„ ë‚´ì˜ ë¹„ìš© ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í•™ìŠµ ê°„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

### âœ¨ ë°ì´í„° ì†ì„± í™•ì¸
`ë°ì´í„°ì…‹`ì˜ ì†ì„±ì€ `ì „ì²˜ë¦¬` ê³¼ì •ì„ 1ì°¨ì ìœ¼ë¡œ ì§„í–‰í•œ ì´í›„ ì•„ë˜ì™€ ê°™ì´ ë‚¨ì•„ ì´ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
|ì†ì„± ëª…|ì„¤ëª…|
|:--:|:--:|
|BillDate|ìˆ˜ì§‘ ì¼ì|
|DemandTypeCodeName|ìƒí’ˆ ëŒ€ë¶„ë¥˜|
|DemandTypeCodeDetailName|ìƒí’ˆ ì†Œë¶„ë¥˜|
|UseAmount|ì‚¬ìš© ë¹„ìš©|
|DemandAmount|ì²­êµ¬ ë¹„ìš©|
|TotalDiscountAmount|í• ì¸ ë¹„ìš©|

## ğŸª¢ Meta Prophetì„ ì´ìš©í•œ ì˜ˆì¸¡
ë¨¼ì € `Meta`ì—ì„œ ì œê³µí•˜ëŠ” `Prophet`ì´ë¼ëŠ” ì‹œê³„ì—´ ë°ì´í„° ì˜ˆì¸¡ì„ ì´ìš©í•´ë³´ì•˜ìŠµë‹ˆë‹¤.  

### ğŸ“² ë°ì´í„° ì „ì²˜ë¦¬
`Prophet`ì€ ë‹¨ë³€ëŸ‰ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê¸°ì— `ì„¤ëª…ë³€ìˆ˜`(`ds`)ì™€ `ì˜ˆì¸¡ë³€ìˆ˜`(`y`)ê°€ í•„ìš”í•©ë‹ˆë‹¤.

ìœ„ ì‚¬í•­ì„ ë§ì¶”ê¸° ìœ„í•´ `ë°ì´í„° ë³€í™˜`ì´ í•„ìš”í•˜ì—¬ ì•„ë˜ì™€ ê°™ì´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.  
ë¨¼ì € `BillDate` ì†ì„± ê¸°ì¤€ `ë°ì´í„°` í†µí•© í›„ `ìƒí’ˆ ë¶„ë¥˜`ì— ëŒ€í•œ ì†ì„±ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.

```python
import pandas as pd
df = pd.read_csv("íŒŒì¼ëª….csv")

df2 = df.groupby(['BillDate']).sum().reset_index()
df2 = df2.drop(['DemandTypeCodeName', 'DemandTypeCodeDetailName'], axis=1)
```

ë°ì´í„° ì¤‘ `BillDate` ì†ì„±ì„ `ds`ë¡œ, `UseAmount`ë¥¼ `y`ë¡œ `DataFrame`ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.

```python
data = pd.DataFrame()
data['ds'] = pd.to_datetime(df2['BillDate'], format='%Y%m%d')
data['y'] = df2['UseAmount']
data = data.reset_index()
data = data.drop('index', axis=1)
```

í•©ì—°ì‚°ì´ ëœ ë°ì´í„°ì´ë¯€ë¡œ `y`ì˜ ë°ì´í„°ì—ì„œ ì´ì „ ë°ì´í„°ë¥¼ ëº„ì…ˆ ì—°ì‚°ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

```python
for i in range(len(data)-1, 0, -1):
  if i == 0:
    continue
  elif data.loc[i]['ds'].day == 1:
    continue
  data.loc[i, 'y'] = (data.loc[i]['y'] - data.loc[i-1]['y'])
```

ì´ëŸ¬í•œ ë°ì´í„°ë¥¼ `Matplot` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ì‹œê°í™”í–ˆê³  ì•„ë˜ì™€ ê°™ì´ í™•ì¸ë©ë‹ˆë‹¤.

```python
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

ax = data['y'].plot(title = "Cost", figsize =(12,4))
ax.set_ylabel('Cost')
plt.ticklabel_format(axis='y', style='plain')
plt.show()
```
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/1.png  =90%x90%)

### ğŸ“ˆ ëª¨ë¸ í•™ìŠµ ë° í™•ì¸
ê°€ê³µëœ ë¹„ìš© ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ `Prophet` ëª¨ë¸ì„ ë§Œë“¤ê³  `ëª¨ë¸` í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- `ëª¨ë¸`ì˜ ê²½ìš° ì£¼ê°„ì˜ ê²½í–¥ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í™•ì¸í•˜ê³  ë°˜ì˜í•˜ë„ë¡ ì„¤ì •í•˜ì˜€ìŠµë‹ˆë‹¤.

```python
model = Prophet(weekly_seasonality=True)
model.fit(data)
```

í•™ìŠµëœ `ëª¨ë¸`ì„ ì´ìš©í•˜ì—¬ 30ì¼ ì´í›„ì˜ ë¹„ìš©ì„ `ì˜ˆì¸¡`ì„ ì§„í–‰í•œ ë’¤ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.  
ë¹„ìš©ì´ ì •ê¸°ì ì¼ ê²½ìš° ë¬¸ì œê°€ ì—†ê² ì§€ë§Œ ì •ê¸°ì ì´ì§€ ì•Šê¸°ì— ì–‘ìƒ ë°˜ì˜ì— ì–´ë ¤ì›€ì´ ë³´ì…ë‹ˆë‹¤.

```python
future = model.make_future_dataframe(periods=30, freq = 'D')
forecast = model.predict(future)
fig = model.plot(forecast, xlabel='Date', ylabel='Cost')
```
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/2.png  =90%x90%)

## ğŸˆ ì„ í˜• íšŒê·€ë¥¼ ì´ìš©í•œ ì˜ˆì¸¡
ì•ì„  `Prophet` ëª¨ë¸ì—ì„œëŠ” ì œëŒ€ë¡œëœ ê²½í–¥ì„± ë°˜ì˜ì„ ëª»í•˜ëŠ” ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.  
ì´ëŸ¬í•œ `ë°ì´í„° ê²½í–¥`ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ `ì„ í˜•íšŒê·€` ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•´ `ì˜ˆì¸¡` í•´ë³´ê² ìŠµë‹ˆë‹¤.

### ğŸ“² ë°ì´í„° ì „ì²˜ë¦¬
ë™ì¼í•˜ê²Œ `BillDate` ì†ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í†µí•© í›„ `ìƒí’ˆ ë¶„ë¥˜` ê´€ë ¨ ì†ì„±ì„ ì‚­ì œí•©ë‹ˆë‹¤.

```python
df2 = df.groupby(['BillDate']).sum().reset_index()
df2 = df2.drop(['DemandTypeCodeName', 'DemandTypeCodeDetailName'], axis=1)
```

ê¸°ì¡´ê³¼ ê°™ì€ `ë°ì´í„°`ë¥¼ ì´ìš©í•˜ì—¬ ì¶”ë¡ í•˜ê¸° ìœ„í•´ `ds`ì™€ `y`ë¥¼ ë‚˜ëˆ„ì–´ ë‘ì—ˆìŠµë‹ˆë‹¤.

```python
data = pd.DataFrame()
data['ds'] = pd.to_datetime(df2['BillDate'], format='%Y%m%d')
data['y'] = df2['UseAmount']
data = data.reset_index()
data = data.drop('index', axis=1)
```

í•©ì—°ì‚°ì´ ëœ `ë°ì´í„°`ì´ë¯€ë¡œ `y`ì˜ `ë°ì´í„°`ì—ì„œ ì´ì „ ë°ì´í„°ë¥¼ ëº„ì…ˆ ì—°ì‚°ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
```python
for i in range(len(data)-1, 0, -1):
  if i == 0:
    continue
  elif data.loc[i]['ds'].day == 1:
    continue
  data.loc[i, 'y'] = (data.loc[i]['y'] - data.loc[i-1]['y'])
```

ë” ë§ì€ `ì†ì„±`ì„ ê°€ì§€ê³  í•™ìŠµí•˜ë„ë¡ 28ì¼ ì´ì „ì˜ `ì‹œê³„ì—´ ë°ì´í„°`ë¥¼ ê°™ì´ ì œê³µí•©ë‹ˆë‹¤.  
ë‹¤ë¥¸ `ì „ì²˜ë¦¬`ê°€ ì™„ë£Œë˜ì–´ ì‹œê°„ ë°ì´í„°ì¸ `ds` ì†ì„±ì„ `Unix Timestamp`ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
```python
for lag in range(1, 29):  # ê³¼ê±° 28ì¼ ë°ì´í„° ì¶”ê°€
    data[f'lag_{lag}'] = data['y'].shift(lag)

data = data.dropna().reset_index(drop=True)
data['ds'] = data['ds'].apply(lambda x: int(x.timestamp()))

data.insert(len(data.columns)-1, 'y', data.pop('y'))
data
```
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/3.png  =90%x90%)

### ğŸ“ˆ ëª¨ë¸ í•™ìŠµ ë° í™•ì¸
`ëª¨ë¸ í•™ìŠµ`ê³¼ `í…ŒìŠ¤íŠ¸`ë¥¼ ìœ„í•´ `í•™ìŠµ ë°ì´í„°`ì™€ `í…ŒìŠ¤íŠ¸ ë°ì´í„°`ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.  
`í…ŒìŠ¤íŠ¸ ë°ì´í„°`ëŠ” ì „ì²´ì—ì„œ ìµœì¢… 30ê°œì˜ `ë°ì´í„°`ë¡œ ì„ ì •í•˜ì—¬ ë¶„í• í•´ë‘ì—ˆìŠµë‹ˆë‹¤.

```python
split_len = len(data)-30

X_train = data[:split_len].iloc[:, :len(df.columns)-2]
y_train = data[:split_len].loc[:, ['y']]

X_test = data[split_len:].iloc[:, :len(df.columns)-2]
y_test = data[split_len:].loc[:, ['y']]
```

`ëª¨ë¸`ì€ `Scikit-learn`ì„ ì´ìš©í•˜ì—¬ `ì„ í˜•íšŒê·€ ëª¨ë¸`ì„ ì„ ì–¸í•˜ì—¬ ì´ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.  
`ëª¨ë¸`ì˜ í•™ìŠµ ê³¼ì •ì—ì„œ ì‚¬ì „ ë¶„ë¦¬í•´ë‘” `_train`ë¡œ ëë‚˜ëŠ” `ë°ì´í„°`ë¥¼ ì´ìš©í•˜ê²Œ ëìŠµë‹ˆë‹¤.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

model = LinearRegression()
model.fit(X_train, y_train)
```

`í•™ìŠµëœ ëª¨ë¸`ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ `X_test` ë³€ìˆ˜ ë°ì´í„°ë¡œ `ê²€ì¦`ì„ ì‹œë„í•˜ì˜€ìŠµë‹ˆë‹¤.  

```python
lrm_predict = model.predict(X_test)
```

`ê²€ì¦ëœ ë°ì´í„°`ë¥¼ ê°€ì§„ ë³€ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ `MSE`ì™€ `MAE`ë¥¼ í†µí•´ `ì†ì‹¤`ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.  
(`R2 Score`ë„ ì´ìš©í•˜ë ¤ í–ˆì§€ë§Œ `ì‹œê³„ì—´ ë°ì´í„°`ì—” ë§ì§€ ì•Šì•„ ì œì™¸í–ˆìŠµë‹ˆë‹¤.)


```python
from sklearn.metrics import mean_squared_error, mean_absolute_error

mse = mean_squared_error(y_test, lrm_predict)
mae = mean_absolute_error(y_test, lrm_predict)

print(mse, mae)
# ì¶œë ¥: 645106360.0808157 20673.465840699464
```

`ëª¨ë¸`ì„ ì´ìš©í•˜ì—¬ `ì˜ˆì¸¡í•œ ê²°ê³¼`ì™€ `í…ŒìŠ¤íŠ¸ ë°ì´í„°`ì˜ ì‹¤ì œ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì•˜ìŠµë‹ˆë‹¤.  
ì œë²• `ë°ì´í„°`ì˜ ê²½í–¥ì„ ì˜ ë°˜ì˜í•˜ì—¬ `ë°ì´í„°`ë¥¼ `ì˜ˆì¸¡`í•œ ê²ƒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
y_test = y_test.reset_index()

plt.clf()
plt.figure(figsize=(12, 8))
plt.plot(y_test['y'], color='red', label='Ideal Fit')
plt.plot(lrm_predict, color='blue')
plt.ticklabel_format(axis='y', style='plain')

plt.show()
```
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/4.png  =90%x90%)

ê·¸ë ‡ë‹¤ë©´ ê¸°ì¡´ì˜ `í•™ìŠµ ë°ì´í„°`ì— ëŒ€í•´ì„œëŠ” ì–´ë–¤ ì–‘ìƒì„ ë³´ì´ëŠ”ì§€ í™•ì¸í•´ë³´ì•˜ìŠµë‹ˆë‹¤.  
`í•™ìŠµ ë°ì´í„°`ì— ëŒ€í•´ì„œë„ ë‚˜ë¦„ì˜ ê²½í–¥ì„ ì˜ ë”°ë¼ê°€ëŠ” ê²ƒì„ í™•ì¸ ê°€ëŠ¥í•œ ìƒíƒœì…ë‹ˆë‹¤.

```python
lrm_predict_train = model.predict(X_train)

plt.clf()
plt.figure(figsize=(12, 8))
plt.plot(y_train['y'], color='red', label='Ideal Fit')
plt.plot(lrm_predict_train, color='blue')
plt.ticklabel_format(axis='y', style='plain')

plt.show()
```
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/5.png  =90%x90%)

## ğŸ’« LSTMì„ ì´ìš©í•œ ì˜ˆì¸¡
`ì„ í˜• íšŒê·€`ë¥¼ ì´ìš©í•œ `ì˜ˆì¸¡`ì—ì„œë„ ë‚˜ë¦„ì˜ ê²½í–¥ì€ ì˜ ì°¾ì•„ê°€ëŠ” ê²ƒì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.  
`LSTM`ì„ ì´ìš©í•˜ì—¬ `ì‹œê³„ì—´ ë°ì´í„°`ë¥¼ ì˜ˆì¸¡í•œë‹¤ë©´ ì–´ë–»ê²Œ ë ì§€ í™•ì¸í•´ë³´ì•˜ìŠµë‹ˆë‹¤.

ìš°ì„  ì´ë²ˆì˜ ê²½ìš° ì„ í˜• íšŒê·€ ê°„ ì œì‘í•œ `y` ì†ì„±ì— ëŒ€í•´ì„œë§Œ ì‚¬ìš©í•˜ë„ë¡ í•˜ì˜€ìŠµë‹ˆë‹¤.

### ğŸ† ê¸°ë³¸ ì„¤ì •
ê¸°ë³¸ì ìœ¼ë¡œ `TensorFlow`ì˜ `Seed`ë¥¼ ê³ ì •í•˜ê³  `GPU` ì‚¬ìš©ì„ ìœ„í•´ ì„¤ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```python
import os
import numpy as np
import tensorflow as tf
import random

seed = 42

os.environ['PYTHONHASHSEED'] = str(seed)
os.environ['TF_DETERMINISTIC_OPS'] = '1'

os.environ["CUDA_VISIBLE_DEVICES"]="0"
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        tf.config.experimental.set_memory_growth(gpus[0], True)
    except RuntimeError as e:
        print(e)
```

### ğŸ˜€ ê´€ë ¨ í•¨ìˆ˜ ìƒì„±
`TensorFlow`ë¥¼ ì´ìš©í•˜ì—¬ ê¸°ë³¸ ì „ì²˜ë¦¬ëœ ë°ì´í„°ì˜ `Sequence`ë¥¼ ì„¤ì •í•˜ëŠ” ë¶€ë¶„ê³¼  
`Batch`, `ì€ë‹‰ì¸µ`ì˜ `Layer`, `Node` ë“±ì„ ì„¤ì •í•  ìˆ˜ ìˆë„ë¡ `í•¨ìˆ˜`ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional

def create_sequences(data, seq_length):
    x = []
    y = []
    for i in range(len(data) - seq_length):
        x.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(x), np.array(y)

def model_train(y, epoch=20, batch_size=32, seq_length=7, hidden_layer=1, hidden_node=1):
  tf.random.set_seed(seed)
  np.random.seed(seed)
  random.seed(seed)

  x_data, y_data = create_sequences(y, seq_length)
  x_data = x_data.reshape((x_data.shape[0], x_data.shape[1], 1))

  split = int(len(x_data)-30)
  x_train, x_test = x_data[:split], x_data[split:]
  y_train, y_test = y_data[:split], y_data[split:]

  model = Sequential()
  if hidden_layer > 1:
    model.add(LSTM(hidden_node, activation='relu', return_sequences=True, input_shape=(seq_length, 1)))
    for _ in range(1, hidden_layer-1):
      model.add(LSTM(hidden_node, activation='relu', return_sequences=True))
    model.add(LSTM(hidden_node, activation='relu', return_sequences=False))
  else:
    model.add(LSTM(hidden_node, activation='relu', return_sequences=False, input_shape=(seq_length, 1)))

  if len(y_train.shape) > 1:
     model.add(Dense(y_train.shape[1]))
  else:
     model.add(Dense(1))

  learning_rate = 0.01
  optimizer = Adam(learning_rate=learning_rate)
  model.compile(optimizer=optimizer, loss='mean_squared_error')

  history = model.fit(x_train, y_train, epochs=epoch, batch_size=batch_size, validation_data=(x_test, y_test), verbose=0)

  return model, x_train, y_train, x_test, y_test, history
```

ì§„í–‰ ê³¼ì •ì—ì„œì˜ `ì†ì‹¤`ê³¼ í•™ìŠµ ì´í›„ì˜ `ì†ì‹¤`ì„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ `í•¨ìˆ˜`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
def history_view(history):
  import matplotlib.pyplot as plt

  plt.figure(figsize=(10, 6))

  plt.plot(history.history['loss'], label='Train Loss')
  plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='dashed')

  plt.title(f'Train Loss')
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.legend()
  plt.grid()
  plt.show()
```

`ëª¨ë¸`ì— íˆ¬ì…ëœ ë°ì´í„°ì™€ `ì˜ˆì¸¡ ê²°ê³¼`ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ `í•¨ìˆ˜`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
def model_view(model, y_train, x_test, y_test):
  y_pred = model.predict(x_test)

  import matplotlib.pyplot as plt

  original_range = range(len(y_train))
  test_range = range(len(y_train), len(y_train) + len(y_test))
  pred_range = range(len(y_train), len(y_train) + len(y_pred))

  plt.figure(figsize=(12, 6))

  plt.plot(original_range, y_train, label="Original Data (Labels)", alpha=0.5)
  plt.plot(test_range, y_test, label="Test Data (Labels)", color='blue')
  plt.plot(pred_range, y_pred, label="Predictions", color='red', linestyle='dashed')

  plt.axvline(len(y_train), color='gray', linestyle='--', label="Train-Test Split")
  plt.legend()
  plt.title("Test Data and Predictions Appended After Original Data")
  plt.xlabel("Index")
  plt.ylabel("Class Label")
  plt.show()
```

### ğŸ“ˆ ëª¨ë¸ í•™ìŠµ ë° í™•ì¸
ìµœì ì˜ `ëª¨ë¸`ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ìœ„ì—ì„œ ìƒì„±í•œ `í•¨ìˆ˜` ìƒ ê° í•­ëª©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.  
- ì´ 450ê°€ì§€ì˜ ê²½ìš°ì˜ ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ `ëª¨ë¸`ì„ ë¹„êµí•˜ê³  ìµœì ì˜ ê²°ê³¼ë¥¼ ì°¾ë„ë¡ í–ˆìŠµë‹ˆë‹¤.

```python
best_epoch = 0
best_batch_size = 0
best_seq_length = 0
best_hidden_node = 0
best_hidden_layer = 0

best_score = -1
best_model = None
best_model_history = None

best_x_train = None
best_y_train = None
best_x_test = None
best_y_test = None

hidden_layers = [1, 2, 3, 4, 5, ]
hidden_nodes = [10, 20, 30, 40, 50, ]
epochs = [10, 20, 30, 40, 50, 60, ]
batch_sizes = [1, ]
seq_lengths = [7, 14, 28, ]

for epoch in epochs:
  for batch_size in batch_sizes:
    for seq_length in seq_lengths:
      for hidden_layer in hidden_layers:
        for hidden_node in hidden_nodes:
          print("NOW:", epoch, batch_size, seq_length, hidden_layer, hidden_node)
          model, x_train, y_train, x_test, y_test, history = model_train(y, epoch, batch_size, seq_length, hidden_layer, hidden_node)
          score = model.evaluate(x_test, y_test, verbose=0)
          print("NOW SCORE:", score)

          if score < best_score or best_score == -1:
            best_epoch = epoch
            best_batch_size = batch_size
            best_seq_length = seq_length
            best_hidden_node = hidden_node
            best_hidden_layer = hidden_layer

            best_score = score
            best_model = model
            best_model_history = history

            best_x_train = x_train
            best_y_train = y_train
            best_x_test = x_test
            best_y_test = y_test
          print("!!NOW BEST!!")
          print(best_epoch, best_batch_size, best_seq_length, best_hidden_layer, best_hidden_node, best_score)

history_view(best_model_history)
model_view(best_model, best_y_train, best_x_test, best_y_test)
# ì¶œë ¥
# Epoch   Batch   Seq   Layer   Node   MSE
# 40       1      7      1      50     381396512.0
```
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/6.png  =90%x90%)
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/7.png  =90%x90%)

ì´ë¥¼ ì‹¤í–‰í•˜ì˜€ì„ ë•Œ ìµœì ì˜ ê°’ì„ ê¸°ì¡´ `ì„ í˜•íšŒê·€`ì™€ì˜ `MSE`ë¥¼ ë¹„êµí•´ë³´ì•˜ìŠµë‹ˆë‹¤.

```plaintext
ì„ í˜•íšŒê·€: 645106360.0808157
MSE: 381396512.0
```

`í…ŒìŠ¤íŠ¸ ë°ì´í„°` ê²€ì¦ë§Œ ìˆ˜í–‰í–ˆì§€ë§Œ `ë°ì´í„° ì˜ˆì¸¡` í›„ `ì‹œê°í™”`í•˜ë„ë¡ í•¨ìˆ˜ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.

```python
def model_none_test_view(model, y_train, x_test, y_test, y_none_test):
  y_pred = model.predict(x_test)

  import matplotlib.pyplot as plt

  original_range = range(len(y_train))
  test_range = range(len(y_train), len(y_train) + len(y_test))
  pred_range = range(len(y_train), len(y_train) + len(y_pred))
  none_test_range = range(len(y_train) + len(y_pred), len(y_train) + len(y_pred) + len(y_none_test))

  plt.figure(figsize=(12, 6))

  plt.plot(original_range, y_train, label="Original Data (Labels)", alpha=0.5)
  plt.plot(test_range, y_test, label="Test Data (Labels)", color='blue')
  plt.plot(pred_range, y_pred, label="Predictions", color='red', linestyle='dashed')
  plt.plot(none_test_range, y_none_test, label="Predictions None test", color='green', linestyle='dashed')

  plt.axvline(len(y_train), color='gray', linestyle='--', label="Train-Test Split")
  plt.legend()
  plt.title("Test Data and Predictions Appended After Original Data")
  plt.xlabel("Index")
  plt.ylabel("Class Label")
  plt.show()
```

`í…ŒìŠ¤íŠ¸ ë°ì´í„°` ì´í›„ 30ì¼ ì¹˜ `ë°ì´í„°`ë¥¼ `ì˜ˆì¸¡`í•œ ë’¤ `ì‹œê°í™”`ë¥¼ ìˆ˜í–‰í•´ë³´ì•˜ìŠµë‹ˆë‹¤.

```python
last_x_test = best_x_test[len(best_x_test)-1].reshape(1, best_x_test.shape[1], 1)
y_total = np.array([])
now = 0

for i in range(30):
  now = best_model.predict(last_x_test)
  last_x_test = np.append(last_x_test[len(last_x_test)-1][1:len(last_x_test[len(last_x_test)-1])], now).reshape(1, best_x_test.shape[1], 1)
  y_total = np.append(y_total, now)

model_none_test_view(best_model, best_y_train, best_x_test, best_y_test, y_total)
```
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/8.png  =90%x90%)

`í•™ìŠµ ë°ì´í„°`ë¥¼ ì´ìš©í–ˆì„ ë•Œ `ì˜ˆì¸¡`ë˜ëŠ”ì§€ í™•ì¸ì„ ìœ„í•´ `ì‹œê°í™” í•¨ìˆ˜`ë¥¼ ìƒì„±í•´ë³´ì•˜ìŠµë‹ˆë‹¤.

```python
def model_all_test_view(model, x_train, y_train, x_test, y_test, y_none_test):
  train_pred = model.predict(x_train)
  y_pred = model.predict(x_test)

  import matplotlib.pyplot as plt

original_range = range(len(y_train))
  test_range = range(len(y_train), len(y_train) + len(y_test))
  pred_range = range(len(y_train), len(y_train) + len(y_pred))
  none_test_range = range(len(y_train) + len(y_pred), len(y_train) + len(y_pred) + len(y_none_test))

  plt.figure(figsize=(12, 6))

  plt.plot(original_range, y_train, label="Original Data (Labels)", alpha=0.5)
  plt.plot(original_range, train_pred, label="Train Test", alpha=0.2)
plt.plot(test_range, y_test, label="Test Data (Labels)", color='blue')
plt.plot(pred_range, y_pred, label="Predictions", color='red', linestyle='dashed')
plt.plot(none_test_range, y_none_test, label="Predictions None test", color='green', linestyle='dashed')

plt.axvline(len(y_train), color='gray', linestyle='--', label="Train-Test Split")
  plt.legend()
  plt.title("Test Data and Predictions Appended After Original Data")
  plt.xlabel("Index")
  plt.ylabel("Class Label")
  plt.show()
```

ìƒˆë¡œ ìƒì„±í•œ `í•¨ìˆ˜`ì— ëŒ€í•´ì„œë„ `ì˜ˆì¸¡`í•´ë³´ì•˜ê³  ê²½í–¥ì´ ì˜ ë°˜ì˜ëœ ê²ƒì´ í™•ì¸ë©ë‹ˆë‹¤.

```python
model_all_test_view(best_model, best_x_train, best_y_train, best_x_test, best_y_test, y_total)
```
![](/assets/image/Post/Personal/Project/LSTM-Cost-predict-project/9.png  =90%x90%)

ì´ë ‡ê²Œ ìµœì ì˜ `ëª¨ë¸`ì„ ë§Œë“¤ê³  ì´ë¥¼ ì´ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

## ğŸ“š ê´€ë ¨ ì½”ë“œ
ì•„ì§ `ì½”ë“œ`ì— ëŒ€í•œ ì •ë¦¬ê°€ ì „ì²´ì ìœ¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì•„ ë³„ë„ ì—…ë¡œë“œë¥¼ í•´ë‘ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.  
ì¶”í›„ ì–´ëŠì •ë„ ì •ë¦¬ë˜ë©´ `.ipynb` í˜•íƒœë¡œ `GitHub` ì €ì¥ì†Œë¥¼ ë§Œë“¤ì–´ ì—…ë¡œë“œ ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ˜… ì•„ì‰¬ìš´ ì 
`ì¸ê³µì§€ëŠ¥ ì•Œê³ ë¦¬ì¦˜`ê³¼ ê°™ì€ ìš”ì†Œì— ëŒ€í•´ ì—¬ëŸ¬ê°€ì§€ ê³µë¶€ë¥¼ ë§ì´ í•´ë³´ì•˜ë‹¤ê³  ìƒê°í•˜ì˜€ëŠ”ë°,  
`LSTM`ì—ì„œì˜ ì¶”ê°€ í•™ìŠµì´ë¼ë˜ê°€ `ì‹œê³„ì—´ ë°ì´í„°`ì˜ `êµì°¨ ê²€ì¦`ì— ëŒ€í•œ ê¶ê¸ˆì¦ì´ ìƒê¹ë‹ˆë‹¤.

í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” í•´ë‹¹ ë¶€ë¶„ì— ëŒ€í•œ ì˜ë¬¸ë§Œ ì œê¸°ëê³  ì‹¤ì œë¡œ `í•™ìŠµ`í•˜ì§€ëŠ” ëª»í•œ ìƒíƒœì…ë‹ˆë‹¤.  
ì¶”í›„ì—ëŠ” ì´ëŸ¬í•œ ë¶€ë¶„ì„ ì¡°ê¸ˆ ë” ì—°êµ¬í•˜ì—¬ `ì¼ë°˜í™”ëœ ëª¨ë¸`ì„ ë§Œë“¤ê³ ì ê³„íš ì¤‘ì…ë‹ˆë‹¤.

## ğŸ˜ í–¥í›„ ê³„íš
ì‚¬ìš©ì ê°„ ì„±í–¥ ì°¨ì´ê°€ ìˆê¸°ì— `ë°ì´í„°`ë¥¼ ì˜ˆì¸¡í•  ë•Œ ê°ìì˜ `ëª¨ë¸`ì„ ë§Œë“¤ê³ ì í–ˆìŠµë‹ˆë‹¤.  
ë‹¤ë§Œ, ì´ ê³¼ì •ì—ì„œ ìµœì ì˜ ê°’ì„ ì°¾ëŠ”ë°ì— ë„ˆë¬´ ì˜¤ëœ ì‹œê°„ì´ ì†Œìš”ë˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.  
(450ê°œ ê²½ìš°ì˜ ìˆ˜ë¡œ ëª¨ë¸ ì œì‘, ë¹„êµ ê°„ ì•½ 5ì‹œê°„ ì”©ì˜ ì‹œê°„ì´ ì†Œìš”ëìŠµë‹ˆë‹¤.) 

ìƒê°í•˜ê³  ìˆëŠ” `í”„ë¡œì„¸ìŠ¤`ëŠ” 6ê°œì›” ì´ìƒì˜ `ë°ì´í„°` ëˆ„ì  ì‹œ ëª¨ë¸ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•˜ê³ ,  
ìƒì„±ëœ `ëª¨ë¸`ì„ ì´ìš©í•´ ë§¤ì›” ì¶”ê°€ë¡œ `í•™ìŠµ`í•˜ì—¬ `ëª¨ë¸`ì˜ í¬ê¸°ë¥¼ ëŠ˜ë ¤ê°ˆê¹Œ ìƒê° ì¤‘ì…ë‹ˆë‹¤.

ì—¬ê¸°ì„œ `Pre-Trained` ëª¨ë¸ í˜•íƒœë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆì„ ê²ƒì¸ë°, ì´ëŠ” ê³ ë¯¼í•´ë³¼ ì‚¬í•­ì…ë‹ˆë‹¤.  
`ì‹œê³„ì—´ ë°ì´í„°` íŠ¹ì„±ì— `ì¶”ê°€ í•™ìŠµ`ì´ ë¬¸ì œê°€ ì—†ì„ì§€ ë“±ì— ëŒ€í•œ ê³ ë¯¼ë„ ë§ì´ë˜ê³  ìˆìŠµë‹ˆë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ ì§€ê¸ˆì€ `ì´ ë¹„ìš©`ë§Œ `ì˜ˆì¸¡`í•˜ì§€ë§Œ, `ê° ìƒí’ˆ ë³„ ë¹„ìš©`ìœ¼ë¡œë„ í™•ì¥í•˜ê³ ì í•©ë‹ˆë‹¤.

- - -

ìƒˆí•´ ì²« ë‚  ì²« í¬ìŠ¤íŒ…ì´ë„¤ìš”! ë‹¤ë“¤ ìƒˆí•´ ë³µ ë§ì´ ë°›ìœ¼ì‹œê³  ì¦ê±°ìš´ í•œ í•´ ë˜ì„¸ìš”!  
ì •ë§ ê¸´ í¬ìŠ¤íŒ… ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ğŸ˜