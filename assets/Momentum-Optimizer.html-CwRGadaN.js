import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,o as t,a as s}from"./app-BHOK313u.js";const o="/assets/image/Post/Computing/AI/Momentum-Optimizer/1.png",a="/assets/image/Post/Computing/AI/Momentum-Optimizer/2.png",n="/assets/image/Post/Computing/AI/Momentum-Optimizer/3.png",c="/assets/image/Post/Computing/AI/Momentum-Optimizer/4.png",r="/assets/image/Post/Computing/AI/Momentum-Optimizer/5.png",p={},d=s('<h2 id="⚽-모멘텀-momentum-은-무엇인가" tabindex="-1"><a class="header-anchor" href="#⚽-모멘텀-momentum-은-무엇인가"><span>⚽ 모멘텀(Momentum)은 무엇인가?</span></a></h2><p><code>모멘텀(Momentum)</code>은 물리학에서 사용되는 용어와 비슷한 개념이라고 보면 될 것 같습니다.<br> 물리학에서는 운동량, 물체가 특정 이동하려고 하는 것을 의미하고 이는 <code>관성</code>이라 보면 됩니다.</p><h3 id="🦾-모멘텀의-고안-이유" tabindex="-1"><a class="header-anchor" href="#🦾-모멘텀의-고안-이유"><span>🦾 모멘텀의 고안 이유</span></a></h3><p><code>모멘텀</code>은 <a href="https://blog.false.kr/posts/Computing/AI/SGD-Minibatch.html" target="_blank" rel="noopener noreferrer">기존 포스팅</a>에서 설명드린 <code>확률적 경사하강법(SGD)</code>의 단점을 보완하기 위한 요소입니다.</p><p>기존의 <code>SGD</code>의 경우 <code>가중치 갱신</code> 과정에서 <code>발산</code> 등의 <code>노이즈</code>로 인해 속도가 느려질 수 있습니다.<br> 속도 문제는 <code>데이터</code>의 <code>차원</code>과 <code>양</code>이 증가하면서 <code>시간</code>적인 부분과 <code>정확성</code>에 대한 문제가 생깁니다.</p><p>이러한 한계를 극복하기 위해 고안된 것이 <code>모멘텀</code>으로 위에서 설명한 <code>관성</code>의 원리를 이용하게 됩니다.</p><h3 id="🤔-모멘텀의-동작-원리" tabindex="-1"><a class="header-anchor" href="#🤔-모멘텀의-동작-원리"><span>🤔 모멘텀의 동작 원리</span></a></h3><p><code>관성</code>을 생각해보면 이전에 발생한 <code>운동량</code>이 현재의 <code>운동량</code>에 영향을 끼치는 것이라 볼 수 있습니다.</p><p><code>모멘텀</code>은 이전에 <code>세대</code>에서 갱신된 <code>가중치</code>와 <code>방향</code>을 이용하여 현재 <code>세대</code>에 일부 적용하는 것입니다.<br> 그렇게 함으로써 <code>SGD</code>에서 발생되는 <code>발산</code>으로 인한 <code>노이즈</code>를 줄이는 역할을 수행할 수 있습니다.</p><p>기존의 <code>SGD</code>와 비교하여 어떠한 양상의 차이가 존재하는지 시각화하여 알아보도록 하겠습니다.</p><figure><img src="'+o+'" alt="" width="70%" height="70%" tabindex="0" loading="lazy"><figcaption>가중치 갱신 비교</figcaption></figure><p><code>SGD</code>에 비해 이전 <code>가중치</code>가 반영되어 <code>발산</code>이 줄어들고 더 멀리 가고 있는 것이 확인됩니다.</p><p>그렇다면 <code>SGD</code>와 수식을 이용하여 <code>가중치</code>를 갱신하는 형식이 어떻게 바뀌었는지 알아보겠습니다.<br> 먼저 <code>SGD</code>로 <code>w(가중치)</code>를 구할 때 기존 <code>w</code>에서 <code>J(손실함수)</code>를 <code>w</code>로 <code>편미분</code>한 값을 빼게 됩니다.</p><figure><img src="'+a+'" alt="" width="50%" height="50%" tabindex="0" loading="lazy"><figcaption>SGD의 가중치 갱신 수식</figcaption></figure><p><code>모멘텀</code>은 기존의 방향 정보를 반영하기 위해 <code>v</code>라는 값을 먼저 계산하도록 유도하게 됩니다.<br><code>v</code>에는 기존 <code>가중치</code>의 반영 정도를 위한 <code>a</code> 값이 있고 해당 값은 0~1 사이의 실수 값입니다.</p><p>이렇게 계산된 <code>v</code> 값을 기존 <code>가중치</code>인 <code>w</code>에 반영하는 형식으로 <code>가중치 갱신</code>이 이뤄집니다.<br> 일반적으로 <code>a</code> 값의 경우 <code>0.5</code> 또는 <code>0.9</code> 등의 값이 사용되는 점도 참고해주시면 좋습니다.</p><figure><img src="'+n+`" alt="" width="50%" height="50%" tabindex="0" loading="lazy"><figcaption>모멘텀의 가중치 갱신 수식</figcaption></figure><p>이를 <code>TensorFlow</code>에서 <code>Optimizer</code>로 사용하는 방법은 아래와 같이 작성하면 됩니다.</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tensorflow.keras.optimizers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> SGD</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">compile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">loss</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;categorical_crossentropy&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">optimizer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">SGD</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">momentum</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.9</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">metrics</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;accuracy&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="😅-모멘텀의-문제점과-네스테로프-모멘텀" tabindex="-1"><a class="header-anchor" href="#😅-모멘텀의-문제점과-네스테로프-모멘텀"><span>😅 모멘텀의 문제점과 네스테로프 모멘텀</span></a></h3><p><code>모멘텀</code>도 문제가 있는데 이전 <code>가중치</code>와 <code>방향</code>을 이용하므로 기울기가 가파른 경우<br><code>관성</code>의 크기로 인해 <code>최저점</code>을 지나치는 <code>Over Shooting(발산)</code> 문제를 야기합니다.</p><p>해당 문제점은 <code>정규화</code> 등을 이용해 경사를 개선할 수도 있으나 다른 방법도 존재하며,<br> 이를 개선하기 위해 고안된 방식이 <code>네스테로프(Nesterov) 모멘텀</code>이라 볼 수 있습니다.</p><p><code>네스테로프 모멘텀</code>은 다음 <code>가중치</code>를 예측한 뒤 현재 <code>가중치</code>에 반영하는 방식입니다.<br><code>가중치</code>가 반영되는 모양을 시각화하여 나타내게 된다면 아래와 같이 나타낼 수 있습니다.</p><figure><img src="`+c+'" alt="" width="70%" height="70%" tabindex="0" loading="lazy"><figcaption>네스테로프 모멘텀의 동작 구조</figcaption></figure><p>그림을 보면 <code>예측 가중치</code>가 존재하는데 이전 갱신된 <code>가중치</code>를 이용해 예측한 것으로,<br> 예측 값을 통해 <code>현재 가중치</code> 값을 갱신하고 이동하는 방식으로 구성된다 볼 수 있습니다.</p><p>이러한 방식을 수식으로 나타내면 아래와 같이 3개의 수식으로 구성되는 것이 확인됩니다.</p><figure><img src="'+r+`" alt="" width="50%" height="50%" tabindex="0" loading="lazy"><figcaption>네스테로프 모멘텀의 가중치 갱신 수식</figcaption></figure><p>처음 계산하게 되는 <code>̃w</code>는 <code>기존 가중치</code>에 <code>기존 가중치</code>에 대한 <code>관성</code>을 반영한 것이며,<br> 계산된 <code>̃w</code> 값을 <code>모멘텀</code>과 같이 갱신 후 <code>관성</code>을 더해 <code>v</code>라는 <code>갱신 가중치</code>를 만듭니다.</p><p>이렇게 계산된 값을 <code>w</code>에 반영하여 <code>예측 가중치</code>를 이용해 <code>현재 가중치</code>를 도출합니다.</p><p>이를 <code>TensorFlow</code>에서 <code>Optimizer</code>로 사용하는 방법은 아래와 같이 작성하면 됩니다.</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tensorflow.keras.optimizers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> SGD</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">compile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">loss</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;categorical_crossentropy&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">optimizer</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">SGD</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">momentum</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.9</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">nesterov</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">metrics</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;accuracy&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><hr><p>이러한 <code>모멘텀</code>에 대한 방식도 존재하지만 이를 개선하기 위한 다른 방법도 존재합니다.<br> 다음 포스팅에서는 다른 방법 중 하나인 <code>적응적 학습률</code> 내용을 포스팅할 예정입니다.</p><p>끝까지 읽어주셔서 감사드립니다. 😎</p>`,34),l=[d];function h(m,k){return t(),i("div",null,l)}const u=e(p,[["render",h],["__file","Momentum-Optimizer.html.vue"]]),A=JSON.parse('{"path":"/posts/Computing/AI/Momentum-Optimizer.html","title":"[Artificial Intelligence] 이전 가중치를 이용하는 모멘텀","lang":"ko-KR","frontmatter":{"title":"[Artificial Intelligence] 이전 가중치를 이용하는 모멘텀","categories":["AI"],"tags":["AI","인공지능","모멘텀","Momentum","옵티마이저","Optimizer","확률적 경사하강법","SGD","네스테로프 모멘텀","Nesterov","Nesterov Momentum","손실","Loss","손실함수","Loss Function"],"date":"2024-11-15T00:00:00.000Z","order":204,"editLink":false,"lastUpdated":true,"description":"⚽ 모멘텀(Momentum)은 무엇인가? 모멘텀(Momentum)은 물리학에서 사용되는 용어와 비슷한 개념이라고 보면 될 것 같습니다. 물리학에서는 운동량, 물체가 특정 이동하려고 하는 것을 의미하고 이는 관성이라 보면 됩니다. 🦾 모멘텀의 고안 이유 모멘텀은 기존 포스팅에서 설명드린 확률적 경사하강법(SGD)의 ...","head":[["meta",{"property":"og:url","content":"https://blog.false.kr/posts/Computing/AI/Momentum-Optimizer.html"}],["meta",{"property":"og:site_name","content":"찬스의 개발 블로그 : Chance Devlog"}],["meta",{"property":"og:title","content":"[Artificial Intelligence] 이전 가중치를 이용하는 모멘텀"}],["meta",{"property":"og:description","content":"⚽ 모멘텀(Momentum)은 무엇인가? 모멘텀(Momentum)은 물리학에서 사용되는 용어와 비슷한 개념이라고 보면 될 것 같습니다. 물리학에서는 운동량, 물체가 특정 이동하려고 하는 것을 의미하고 이는 관성이라 보면 됩니다. 🦾 모멘텀의 고안 이유 모멘텀은 기존 포스팅에서 설명드린 확률적 경사하강법(SGD)의 ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://blog.false.kr/assets/image/Post/Computing/AI/Momentum-Optimizer/1.png \\"가중치 갱신 비교\\" =70%x70%"}],["meta",{"property":"og:locale","content":"ko-KR"}],["meta",{"property":"og:updated_time","content":"2024-11-17T12:29:46.000Z"}],["meta",{"property":"article:author","content":"Chance"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:tag","content":"인공지능"}],["meta",{"property":"article:tag","content":"모멘텀"}],["meta",{"property":"article:tag","content":"Momentum"}],["meta",{"property":"article:tag","content":"옵티마이저"}],["meta",{"property":"article:tag","content":"Optimizer"}],["meta",{"property":"article:tag","content":"확률적 경사하강법"}],["meta",{"property":"article:tag","content":"SGD"}],["meta",{"property":"article:tag","content":"네스테로프 모멘텀"}],["meta",{"property":"article:tag","content":"Nesterov"}],["meta",{"property":"article:tag","content":"Nesterov Momentum"}],["meta",{"property":"article:tag","content":"손실"}],["meta",{"property":"article:tag","content":"Loss"}],["meta",{"property":"article:tag","content":"손실함수"}],["meta",{"property":"article:tag","content":"Loss Function"}],["meta",{"property":"article:published_time","content":"2024-11-15T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-11-17T12:29:46.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"[Artificial Intelligence] 이전 가중치를 이용하는 모멘텀\\",\\"image\\":[\\"https://blog.false.kr/assets/image/Post/Computing/AI/Momentum-Optimizer/1.png \\\\\\"가중치 갱신 비교\\\\\\" =70%x70%\\",\\"https://blog.false.kr/assets/image/Post/Computing/AI/Momentum-Optimizer/2.png \\\\\\"SGD의 가중치 갱신 수식\\\\\\" =50%x50%\\",\\"https://blog.false.kr/assets/image/Post/Computing/AI/Momentum-Optimizer/3.png \\\\\\"모멘텀의 가중치 갱신 수식\\\\\\" =50%x50%\\",\\"https://blog.false.kr/assets/image/Post/Computing/AI/Momentum-Optimizer/4.png \\\\\\"네스테로프 모멘텀의 동작 구조\\\\\\" =70%x70%\\",\\"https://blog.false.kr/assets/image/Post/Computing/AI/Momentum-Optimizer/5.png \\\\\\"네스테로프 모멘텀의 가중치 갱신 수식\\\\\\" =50%x50%\\"],\\"datePublished\\":\\"2024-11-15T00:00:00.000Z\\",\\"dateModified\\":\\"2024-11-17T12:29:46.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Chance\\",\\"url\\":\\"https://blog.false.kr\\",\\"email\\":\\"chance0432@naver.com\\"}]}"]]},"headers":[{"level":2,"title":"⚽ 모멘텀(Momentum)은 무엇인가?","slug":"⚽-모멘텀-momentum-은-무엇인가","link":"#⚽-모멘텀-momentum-은-무엇인가","children":[{"level":3,"title":"🦾 모멘텀의 고안 이유","slug":"🦾-모멘텀의-고안-이유","link":"#🦾-모멘텀의-고안-이유","children":[]},{"level":3,"title":"🤔 모멘텀의 동작 원리","slug":"🤔-모멘텀의-동작-원리","link":"#🤔-모멘텀의-동작-원리","children":[]},{"level":3,"title":"😅 모멘텀의 문제점과 네스테로프 모멘텀","slug":"😅-모멘텀의-문제점과-네스테로프-모멘텀","link":"#😅-모멘텀의-문제점과-네스테로프-모멘텀","children":[]}]}],"git":{"createdTime":1731419100000,"updatedTime":1731846586000,"contributors":[{"name":"Chance","email":"ahs0432@naver.com","commits":6},{"name":"ahs0432","email":"ahs0432@naver.com","commits":3}]},"readingTime":{"minutes":0.48,"words":145},"filePathRelative":"posts/Computing/AI/Momentum-Optimizer.md","localizedDate":"2024년 11월 15일","excerpt":"<h2>⚽ 모멘텀(Momentum)은 무엇인가?</h2>\\n<p><code>모멘텀(Momentum)</code>은 물리학에서 사용되는 용어와 비슷한 개념이라고 보면 될 것 같습니다.<br>\\n물리학에서는 운동량, 물체가 특정 이동하려고 하는 것을 의미하고 이는 <code>관성</code>이라 보면 됩니다.</p>\\n<h3>🦾 모멘텀의 고안 이유</h3>\\n<p><code>모멘텀</code>은 <a href=\\"https://blog.false.kr/posts/Computing/AI/SGD-Minibatch.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">기존 포스팅</a>에서 설명드린 <code>확률적 경사하강법(SGD)</code>의 단점을 보완하기 위한 요소입니다.</p>","autoDesc":true}');export{u as comp,A as data};
